{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhWRIYAJiHyL"
      },
      "source": [
        "**Content-only music recommender that uses STFT-derived features and MFCCs to return nearest neighbors.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAbSjvrC7sfZ",
        "outputId": "0c3749cf-55dc-44c7-ae7c-ef83c7a65836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG__RYwRbnd7"
      },
      "source": [
        "**COMPILING AUDIO DATASET USING FMA DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs and imports all required libraries for data and audio processing. The !pip command ensures the correct versions of pandas, librosa, and soundfile are installed for consistent behavior. The imports load general utilities (os, io, zipfile, random, csv, math), numerical and data tools (numpy, pandas), and audio libraries (librosa, soundfile) used for reading, analyzing, and saving WAV files."
      ],
      "metadata": {
        "id": "CFEFGbs4F3xr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-FVKgTLG3GK",
        "outputId": "09e8f977-475d-4e17-ff7b-57542eadddfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# FMA-small → WAV mini-dataset builder\n",
        "# Defaults: N_SAMPLES = 40, SR = 22050, MONO WAV, 30 s clips\n",
        "\n",
        "!pip -q install pandas==2.2.2 librosa==0.10.2.post1 soundfile==0.12.1\n",
        "\n",
        "import os, io, zipfile, random, csv, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa, soundfile as sf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines key settings for the mini audio dataset. The code specifies how many tracks to sample (N_SAMPLES), sets a uniform sampling rate of 22,050 Hz, fixes each clip length at 30 seconds, and locks randomness with a seed for reproducibility. It also prepares output folders—project_dataset/clips—ensuring they exist before any files are saved."
      ],
      "metadata": {
        "id": "vshJqIkZFLLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CRtkTosHewN"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "\n",
        "N_SAMPLES   = 40           # choose any 30–80\n",
        "SR          = 22050        # target sample rate\n",
        "CLIP_SEC    = 30           # enforce 30 s\n",
        "SEED        = 123\n",
        "\n",
        "OUT_DIR     = \"project_dataset\"\n",
        "CLIPS_DIR   = os.path.join(OUT_DIR, \"clips\")\n",
        "os.makedirs(CLIPS_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifies download links for the FMA-small audio dataset and its metadata, then defines a helper function wget() to fetch them safely. The function uses Python’s subprocess to run a shell command that quietly downloads a file while showing progress. If the download fails, it raises an error to alert the user, ensuring that missing or corrupted files are caught early."
      ],
      "metadata": {
        "id": "jITGMqjAGhYk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM5LzUc1I0IM"
      },
      "outputs": [],
      "source": [
        "# FMA-small audio and metadata zips\n",
        "\n",
        "AUDIO_ZIP_URL = \"https://os.unil.cloud.switch.ch/fma/fma_small.zip\"\n",
        "META_ZIP_URL  = \"https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\"\n",
        "\n",
        "def wget(url, out):\n",
        "    import subprocess, shlex, textwrap\n",
        "    cmd = f\"wget -q --show-progress -O {shlex.quote(out)} {shlex.quote(url)}\"\n",
        "    print(f\"Downloading: {url}\")\n",
        "    r = subprocess.run(cmd, shell=True)\n",
        "    if r.returncode != 0:\n",
        "        raise RuntimeError(f\"wget failed for {url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the FMA-small dataset directly from its online source using the wget command. The exclamation mark runs the command in Colab’s shell environment, fetching the ZIP file so it can later be extracted and processed for feature generation."
      ],
      "metadata": {
        "id": "UACIYt5eHDUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ_Hk73OPlec",
        "outputId": "ce8558ac-55da-4b69-9740-e8447bfaa797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-31 14:25:56--  https://os.unil.cloud.switch.ch/fma/fma_small.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.16, 2001:620:5ca1:201::214\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7679594875 (7.2G) [application/zip]\n",
            "Saving to: ‘fma_small.zip’\n",
            "\n",
            "fma_small.zip       100%[===================>]   7.15G  34.9MB/s    in 4m 3s   \n",
            "\n",
            "2025-10-31 14:30:00 (30.1 MB/s) - ‘fma_small.zip’ saved [7679594875/7679594875]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://os.unil.cloud.switch.ch/fma/fma_small.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks whether the FMA-small and metadata ZIP files already exist in the workspace. If they don’t, the wget() function is called to download them. This prevents redundant downloads and ensures both the audio dataset and its metadata are available for later processing."
      ],
      "metadata": {
        "id": "kl7Xqal-HI9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC4-WL4_O0BL",
        "outputId": "be549f4e-1237-4df2-dbd6-231215f63507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n"
          ]
        }
      ],
      "source": [
        "# Download missing zips\n",
        "\n",
        "if not os.path.exists(\"fma_small.zip\"):\n",
        "    wget(AUDIO_ZIP_URL, \"fma_small.zip\")\n",
        "if not os.path.exists(\"fma_metadata.zip\"):\n",
        "    wget(META_ZIP_URL, \"fma_metadata.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handles extraction of the downloaded audio dataset. If the fma_small folder doesn’t exist, it opens the ZIP file and extracts its contents to the current directory, displaying a short progress message. If the folder is already present, it simply skips extraction to save time and avoid overwriting existing files."
      ],
      "metadata": {
        "id": "8Bo-Dji3HO1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl2mkFTiYNj1",
        "outputId": "742ceffb-e128-4c4d-9b2f-2bcf97790d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio already extracted.\n"
          ]
        }
      ],
      "source": [
        "# Unzip Audio to ./fma_small/\n",
        "\n",
        "if not os.path.exists(\"fma_small\"):\n",
        "    print(\"Extracting fma_small.zip ...\")\n",
        "    with zipfile.ZipFile(\"fma_small.zip\", \"r\") as z:\n",
        "        z.extractall(\".\")\n",
        "else:\n",
        "    print(\"Audio already extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracts the metadata ZIP file containing track information such as genre labels and artist details. If the fma_metadata folder doesn’t exist, it unzips the contents into the current directory; otherwise, it skips extraction and confirms that the metadata is already available."
      ],
      "metadata": {
        "id": "25caIQdAHpZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CimTisIjYWZ_",
        "outputId": "f05ee932-2ba5-4ef9-a09f-4d758fc7637d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting fma_metadata.zip ...\n"
          ]
        }
      ],
      "source": [
        "# Unzip metadata to ./fma_metadata/\n",
        "\n",
        "if not os.path.exists(\"fma_metadata\"):\n",
        "    print(\"Extracting fma_metadata.zip ...\")\n",
        "    with zipfile.ZipFile(\"fma_metadata.zip\", \"r\") as z:\n",
        "        z.extractall(\".\")\n",
        "else:\n",
        "    print(\"Metadata already extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the main metadata file tracks.csv using pandas, which contains detailed information about each track in the FMA dataset. The CSV has a hierarchical column structure, so the code flattens it by joining each level (e.g., ('track', 'title')) into a single string like track.title. This makes the DataFrame easier to work with when selecting or filtering specific attributes later in the workflow."
      ],
      "metadata": {
        "id": "3j55-Zx9H0A9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r739vLHRYqij"
      },
      "outputs": [],
      "source": [
        "# tracks.csv is a multi-index column CSV so flatten it for easy access.\n",
        "\n",
        "tracks_csv_path = \"fma_metadata/tracks.csv\"\n",
        "tracks = pd.read_csv(tracks_csv_path, header=[0,1], index_col=0)\n",
        "\n",
        "# Flatten multiindex columns like ('track','title') → 'track.title'\n",
        "tracks.columns = ['{}.{}'.format(a,b) for a,b in tracks.columns.values]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selects only the relevant metadata fields needed for the recommender—track title, main genre, and artist name. It first checks that these columns exist in the dataset and raises an error if any are missing. Then it copies those columns into a new DataFrame called meta and renames them to simpler labels (title, artist, genre) for easier reference in later processing and output."
      ],
      "metadata": {
        "id": "TtavngrhH59Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dXm8PRZZt9-"
      },
      "outputs": [],
      "source": [
        "# Keeping only the fields we need\n",
        "\n",
        "keep_cols = [\n",
        "    'track.title',\n",
        "    'track.genre_top',\n",
        "    'artist.name'\n",
        "]\n",
        "missing_cols = [c for c in keep_cols if c not in tracks.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"Missing expected columns in tracks.csv: {missing_cols}\")\n",
        "\n",
        "meta = tracks[keep_cols].copy()\n",
        "meta.rename(columns={\n",
        "    'track.title': 'title',\n",
        "    'artist.name': 'artist',\n",
        "    'track.genre_top': 'genre'\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fills any missing metadata values with the placeholder 'unknown'. This ensures that every track has a defined title, artist, and genre, preventing errors or empty fields during later stages like sampling, labeling, or displaying recommendations."
      ],
      "metadata": {
        "id": "EBtfRuzwISJm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn5XVg5aZ5rK"
      },
      "outputs": [],
      "source": [
        "# Substitute rows may have NaNs with 'unknown'\n",
        "\n",
        "meta['title']  = meta['title'].fillna('unknown')\n",
        "meta['artist'] = meta['artist'].fillna('unknown')\n",
        "meta['genre']  = meta['genre'].fillna('unknown')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a helper function to locate each track’s MP3 file within the nested FMA-small folder structure, where filenames follow a six-digit ID format. It then loops through all track IDs in the metadata, checks if each corresponding audio file exists, and collects the valid ones in available. Finally, it prints how many tracks actually have audio files available for processing."
      ],
      "metadata": {
        "id": "vycwuMc8IbxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2eZ5PL1aGqt",
        "outputId": "7a773bfa-ebe0-41b2-c1b6-18908d1e4ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracks with audio present: 5230\n"
          ]
        }
      ],
      "source": [
        "# discover available MP3 files\n",
        "# Audio files are named by 6-digit track id in nested folders:\n",
        "# fma_small/000/000002.mp3 for track_id 2, etc.\n",
        "\n",
        "def id_to_mp3_path(tid: int) -> str:\n",
        "    tid6 = f\"{tid:06d}\"\n",
        "    folder = tid6[:3]\n",
        "    return os.path.join(\"fma_small\", folder, f\"{tid6}.mp3\")\n",
        "\n",
        "available = []\n",
        "for tid in meta.index.tolist():\n",
        "    p = id_to_mp3_path(int(tid))\n",
        "    if os.path.exists(p):\n",
        "        available.append(int(tid))\n",
        "\n",
        "print(f\"Tracks with audio present: {len(available)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selects a random subset of tracks from the available audio files to create a manageable mini-dataset. The random seed ensures the same selection each time for reproducibility. If no audio files are found, it raises an error to flag the issue. Otherwise, it randomly picks up to N_SAMPLES tracks and prints how many were selected."
      ],
      "metadata": {
        "id": "9Rxvm6BYIjMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N2UCNkXaQYB",
        "outputId": "603a61d1-fae0-4141-b948-4a9fd4395bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling 40 tracks.\n"
          ]
        }
      ],
      "source": [
        "# Sampling a subset\n",
        "\n",
        "random.seed(SEED)\n",
        "if len(available) == 0:\n",
        "    raise RuntimeError(\"No audio files found; check that fma_small extracted correctly.\")\n",
        "pick = random.sample(available, k=min(N_SAMPLES, len(available)))\n",
        "print(f\"Sampling {len(pick)} tracks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates 30-second WAV clips and builds a matching metadata table. For each randomly chosen track, it loads the MP3 file with librosa, resampling to 22,050 Hz, converting to mono, and trimming or padding the waveform to ensure a consistent 30-second length. The processed audio is then saved as a 16-bit PCM WAV file in the clips folder. Alongside this, key metadata track ID, title, artist, genre, and file path is gathered into a rows list that will later form the metadata.csv file."
      ],
      "metadata": {
        "id": "cCnKopnZIr_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "669H9A3AabfQ"
      },
      "outputs": [],
      "source": [
        "# Export WAV + build metadata.csv\n",
        "\n",
        "rows = [(\"track_id\",\"title\",\"artist\",\"genre\",\"path\")]\n",
        "target_len = SR * CLIP_SEC\n",
        "\n",
        "for i, tid in enumerate(pick, start=1):\n",
        "    mp3_path = id_to_mp3_path(tid)\n",
        "    # Load MP3, resample to SR, mono, duration 30 s\n",
        "    # librosa.load will trim to duration, but we ensure exact length by pad/truncate\n",
        "    y, sr = librosa.load(mp3_path, sr=SR, mono=True, duration=CLIP_SEC)\n",
        "    if len(y) < target_len:\n",
        "        y = np.pad(y, (0, target_len - len(y)))\n",
        "    elif len(y) > target_len:\n",
        "        y = y[:target_len]\n",
        "\n",
        "    # Write as WAV PCM_16\n",
        "    out_name = f\"{i:03d}.wav\"\n",
        "    out_path = os.path.join(CLIPS_DIR, out_name)\n",
        "    sf.write(out_path, y.astype(np.float32), SR, subtype=\"PCM_16\")\n",
        "\n",
        "    # Metadata fields\n",
        "    m = meta.loc[tid]\n",
        "    title  = str(m['title'])\n",
        "    artist = str(m['artist'])\n",
        "    genre  = str(m['genre']) if pd.notna(m['genre']) else 'unknown'\n",
        "\n",
        "    rows.append((str(tid), title, artist, genre, f\"clips/{out_name}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writes all collected track information to a CSV file for easy reference. It saves the rows list containing each clip’s ID, title, artist, genre, and relative path to metadata.csv inside the project folder. The print statements confirm successful completion, showing where the WAV clips and metadata file were stored."
      ],
      "metadata": {
        "id": "O7v_qL9lIzxf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDuqd0SFbezH",
        "outputId": "48167d40-b1ce-48d7-c7c6-e78b1c64b423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done.\n",
            "Saved WAV clips → project_dataset/clips\n",
            "Metadata CSV   → project_dataset/metadata.csv\n"
          ]
        }
      ],
      "source": [
        "# Save CSV\n",
        "meta_csv_path = os.path.join(OUT_DIR, \"metadata.csv\")\n",
        "with open(meta_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(rows)\n",
        "\n",
        "print(\"\\nDone.\")\n",
        "print(f\"Saved WAV clips → {CLIPS_DIR}\")\n",
        "print(f\"Metadata CSV   → {meta_csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displays the first few entries of the rows list to verify that metadata and file paths were recorded correctly. This quick check helps confirm that each WAV file has its corresponding track ID, title, artist, and genre before proceeding to feature extraction or further analysis."
      ],
      "metadata": {
        "id": "iIzxRQT-I8-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BGDMXANbi_U",
        "outputId": "2a76de8d-ac6e-46b8-cbf3-570cef6b6b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('track_id', 'title', 'artist', 'genre', 'path')\n",
            "('10440', 'No Gravity Blues', 'Big Blood', 'Folk', 'clips/001.wav')\n",
            "('53576', 'River', 'Mary Lorson', 'Folk', 'clips/002.wav')\n",
            "('14653', 'Bad Sign', 'Brad Sucks', 'Rock', 'clips/003.wav')\n",
            "('73761', 'Weapons', 'Dad Rocks!', 'International', 'clips/004.wav')\n",
            "('53229', 'Cocaine', 'Fruit Flesh', 'Pop', 'clips/005.wav')\n",
            "('20667', 'surprisingly upbeat about it', 'Vim', 'Electronic', 'clips/006.wav')\n",
            "('6603', 'The Woods', 'Height With Friends', 'Hip-Hop', 'clips/007.wav')\n",
            "('69833', 'Dreamflower (Keep The Dream Alive) (Instrumental)', 'The Honorable Sleaze', 'Hip-Hop', 'clips/008.wav')\n",
            "('98205', 'Mankind', 'Ezylohm_tek', 'Electronic', 'clips/009.wav')\n"
          ]
        }
      ],
      "source": [
        "# Peek at first ten rows\n",
        "for r in rows[:10]:\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDNMuv-3iZZO"
      },
      "source": [
        "**Short-Time Fourier Transform (STFT)**\n",
        "\n",
        "Compute STFT magnitude spectrogram |X(n,k)|, with typical parameters: FFT size 2048, hop length 512, Hann window. Derive summary features like spectral centroid, roll-off, flatness, and zero-crossing rate from time frames, then aggregate with mean and standard deviation across time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs and imports all essential libraries for the feature extraction and recommendation phase. The !pip command ensures consistent versions of key packages like librosa, soundfile, and scikit-learn. Core modules (os, math, json, random, warnings) handle file operations and configuration, while dataclasses helps structure feature records. NumPy and pandas support numerical and tabular processing, tqdm provides progress bars, and librosa manages audio analysis and visualization. StandardScaler and cosine_similarity from scikit-learn are later used to normalize features and compute track similarity. The last line suppresses warning messages for cleaner notebook output."
      ],
      "metadata": {
        "id": "9l51Cy1TJUox"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-IgoEiZnTqX",
        "outputId": "cbb5feeb-8632-4235-9d41-78ba65215967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/253.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install librosa==0.10.1 soundfile==0.12.1 numpy pandas scikit-learn tqdm --quiet\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sets up reproducibility and file paths for the feature extraction process. The seed values ensure that any random sampling or ordering produces identical results across runs. It then defines key directory paths: DATA_DIR for the project’s main data folder, AUDIO_DIR for the audio clips, and TRACKS_CSV and FEATURES_CSV for storing track metadata and extracted audio features respectively."
      ],
      "metadata": {
        "id": "SQDBB3p1Ji4k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H7e13LenphF"
      },
      "outputs": [],
      "source": [
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = \"/content/data\"\n",
        "AUDIO_DIR = os.path.join(DATA_DIR, \"audio\")\n",
        "TRACKS_CSV = os.path.join(DATA_DIR, \"tracks.csv\")\n",
        "FEATURES_CSV = os.path.join(DATA_DIR, \"features.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the core audio analysis and evaluation settings for the recommender system. The sample rate (SR) and clip duration determine how audio is processed, while N_FFT, HOP_LENGTH, and WIN configure the Short-Time Fourier Transform used to extract spectral features. Parameters like N_MELS and N_MFCC set the number of mel bands and MFCC coefficients to compute. Flags such as INCLUDE_DELTAS, COMPUTE_TEMPO, and COMPUTE_CHROMA control optional feature extraction steps. TOPK specifies how many similar tracks to return, and the final two flags toggle whether to evaluate similarity by genre or artist."
      ],
      "metadata": {
        "id": "5_ZhXTSaJqd8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZtIKXcInvC8"
      },
      "outputs": [],
      "source": [
        "# Audio/Feature parameters\n",
        "\n",
        "SR = 22050\n",
        "CLIP_SECONDS = 30\n",
        "\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "WIN = \"hann\"\n",
        "\n",
        "N_MELS = 128\n",
        "N_MFCC = 13\n",
        "\n",
        "INCLUDE_DELTAS = False # Set True to append Δ and ΔΔ MFCCs\n",
        "\n",
        "# Optional add-ons\n",
        "COMPUTE_TEMPO = True\n",
        "COMPUTE_CHROMA = False # Set True to add key-aware scalar features\n",
        "\n",
        "TOPK = 5 # Number of neighbors to return\n",
        "\n",
        "# Evaluation\n",
        "EVAL_GENRE = True\n",
        "EVAL_ARTIST = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines lightweight data structures and helpers for getting audio into a consistent form and extracting core spectral features. TrackMeta is a small record that holds the fields your pipeline needs per track (ID, title, artist, genre, path). load_tracks_csv reads the tracks CSV, validates required columns, and returns a list of TrackMeta objects as clean, string typed entries so downstream code doesn’t break on NaNs.\n",
        "load_audio_centered loads mono audio at the target sample rate, then takes a centered window if the file is longer than the desired clip length. It trims leading/trailing silence (30 dB threshold) and peak normalizes so loud files don’t dominate feature scales. The function returns the waveform and sample rate ready for analysis.\n",
        "spectral_features computes a magnitude STFT, derives a power spectrogram, and then summarizes framewise descriptors spectral centroid, roll-off (85%), flatness, and zero-crossing rate by their mean and standard deviation to get time invariant features per clip. If tempo is enabled, it builds an onset envelope, estimates tempo robustly (handling empty/failed cases by returning NaN), and appends it to the feature dict. It returns both the feature dictionary and the power spectrogram, which can be reused for mel or other downstream calculations."
      ],
      "metadata": {
        "id": "4UUiK6l1Jxu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knmdJ62joGNz"
      },
      "outputs": [],
      "source": [
        "# Preprocessing, feature extraction, aggregation, and I/O\n",
        "\n",
        "@dataclass\n",
        "class TrackMeta:\n",
        "    track_id: str\n",
        "    title: str\n",
        "    artist: str\n",
        "    genre: str\n",
        "    path: str\n",
        "\n",
        "\n",
        "def load_tracks_csv(csv_path: str) -> list:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    required = {\"track_id\", \"title\", \"artist\", \"genre\", \"path\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"tracks.csv missing columns: {missing}\")\n",
        "    rows = []\n",
        "    for _, r in df.iterrows():\n",
        "        rows.append(TrackMeta(\n",
        "            track_id=str(r[\"track_id\"]),\n",
        "            title=str(r[\"title\"]),\n",
        "            artist=str(r[\"artist\"]),\n",
        "            genre=str(r[\"genre\"]) if not pd.isna(r[\"genre\"]) else \"\",\n",
        "            path=str(r[\"path\"]) ))\n",
        "    return rows\n",
        "\n",
        "\n",
        "def load_audio_centered(path: str, sr: int = SR, clip_seconds: int = CLIP_SECONDS):\n",
        "    \"\"\"Load mono audio and take a centered window of length clip_seconds if audio is longer.\"\"\"\n",
        "    y, sr = librosa.load(path, sr=sr, mono=True)\n",
        "    target_len = clip_seconds * sr\n",
        "    if len(y) > target_len:\n",
        "        start = (len(y) - target_len) // 2\n",
        "        y = y[start:start+target_len]\n",
        "    y, _ = librosa.effects.trim(y, top_db=30)   # Simple silence trimming at edges\n",
        "    peak = np.max(np.abs(y)) if len(y) else 1.0   # Peak normalize to prevent loudness dominance\n",
        "    if peak > 0:\n",
        "        y = y / peak\n",
        "    return y, sr\n",
        "\n",
        "\n",
        "def spectral_features(y: np.ndarray, sr: int):\n",
        "    S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH, window=WIN))\n",
        "    # Power spectrogram for mel and contrast\n",
        "    S_power = (S ** 2)\n",
        "\n",
        "    # Spectral stats over time\n",
        "    centroid = librosa.feature.spectral_centroid(S=S, sr=sr)\n",
        "    rolloff = librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=0.85)\n",
        "    flatness = librosa.feature.spectral_flatness(S=S)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y, frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
        "\n",
        "    feats = {\n",
        "        \"centroid_mean\": float(np.mean(centroid)), \"centroid_std\": float(np.std(centroid)),\n",
        "        \"rolloff_mean\": float(np.mean(rolloff)), \"rolloff_std\": float(np.std(rolloff)),\n",
        "        \"flatness_mean\": float(np.mean(flatness)), \"flatness_std\": float(np.std(flatness)),\n",
        "        \"zcr_mean\": float(np.mean(zcr)), \"zcr_std\": float(np.std(zcr)),\n",
        "    }\n",
        "\n",
        "    # Tempo\n",
        "    if COMPUTE_TEMPO:\n",
        "        try:\n",
        "            onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=HOP_LENGTH)\n",
        "            if onset_env is None or len(onset_env) == 0:\n",
        "                tempo_val = np.nan\n",
        "            else:\n",
        "                tempo_est = librosa.beat.tempo(onset_envelope=onset_env, sr=sr, hop_length=HOP_LENGTH, aggregate=np.median)\n",
        "                # tempo_est can be a scalar or ndarray([value])\n",
        "                if isinstance(tempo_est, np.ndarray):\n",
        "                    tempo_val = float(tempo_est.flat[0]) if tempo_est.size > 0 else np.nan\n",
        "                else:\n",
        "                    tempo_val = float(tempo_est)\n",
        "        except Exception:\n",
        "              tempo_val = np.nan\n",
        "        # Ensure feats is a dictionary before adding to it\n",
        "        if not isinstance(feats, dict):\n",
        "            feats = {}\n",
        "        feats[\"tempo\"] = tempo_val\n",
        "\n",
        "    return feats, S_power"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implements an auxiliary feature extractor that focuses on pitch related information. It loads the audio file with librosa, computes its Short-Time Fourier Transform, and squares the magnitude to get a power spectrogram. If chroma computation is enabled, it derives a 12-dimensional chroma vector (one per semitone) averaged across time to capture harmonic and key characteristics of the track. In case of errors or missing values, it fills them with zeros for numerical stability. The function returns both the cleaned feature dictionary and the power spectrogram for any later processing."
      ],
      "metadata": {
        "id": "31bRJCccKWQe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbOl-RlIYnkF"
      },
      "outputs": [],
      "source": [
        "def extract_features(filepath, COMPUTE_CHROMA=True):\n",
        "    feats = {}\n",
        "\n",
        "    y, sr = librosa.load(filepath)\n",
        "    S = np.abs(librosa.stft(y))\n",
        "    S_power = S**2\n",
        "\n",
        "    # Chroma/key\n",
        "    if COMPUTE_CHROMA:\n",
        "        try:\n",
        "            chroma = librosa.feature.chroma_stft(S=S_power, sr=sr)\n",
        "            chroma_mean = np.mean(chroma, axis=1)\n",
        "            for i, v in enumerate(chroma_mean):\n",
        "                feats[f\"chroma_mean_{i}\"] = float(v)\n",
        "        except Exception:\n",
        "            for i in range(12):\n",
        "                feats[f\"chroma_mean_{i}\"] = np.nan\n",
        "\n",
        "    # Clean up NaN/Inf\n",
        "    for k, v in list(feats.items()):\n",
        "        if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))):\n",
        "            feats[k] = 0.0\n",
        "\n",
        "    return feats, S_power\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a data directory and downloads the FMA metadata ZIP file into it. The !mkdir -p command ensures the /content/data folder exists, wget fetches the metadata archive from the official source, and unzip -o extracts its contents into the same directory, overwriting old files if needed. This prepares the metadata for use in feature extraction and analysis."
      ],
      "metadata": {
        "id": "AAN2wT5ZKgvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b-QCEdhajoA",
        "outputId": "162aadd6-0cdf-4a8e-e4a9-2e3a2fd4fd75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-31 14:52:52--  https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.16, 2001:620:5ca1:201::214\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358412441 (342M) [application/zip]\n",
            "Saving to: ‘/content/data/fma_metadata.zip’\n",
            "\n",
            "/content/data/fma_m 100%[===================>] 341.81M  27.2MB/s    in 13s     \n",
            "\n",
            "2025-10-31 14:53:06 (25.6 MB/s) - ‘/content/data/fma_metadata.zip’ saved [358412441/358412441]\n",
            "\n",
            "Archive:  /content/data/fma_metadata.zip\n",
            " bunzipping: /content/data/fma_metadata/README.txt  \n",
            " bunzipping: /content/data/fma_metadata/checksums  \n",
            " bunzipping: /content/data/fma_metadata/not_found.pickle  \n",
            " bunzipping: /content/data/fma_metadata/raw_genres.csv  \n",
            " bunzipping: /content/data/fma_metadata/raw_albums.csv  \n",
            " bunzipping: /content/data/fma_metadata/raw_artists.csv  \n",
            " bunzipping: /content/data/fma_metadata/raw_tracks.csv  \n",
            " bunzipping: /content/data/fma_metadata/tracks.csv  \n",
            " bunzipping: /content/data/fma_metadata/genres.csv  \n",
            " bunzipping: /content/data/fma_metadata/raw_echonest.csv  \n",
            " bunzipping: /content/data/fma_metadata/echonest.csv  \n",
            " bunzipping: /content/data/fma_metadata/features.csv  \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/data\n",
        "!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip -O /content/data/fma_metadata.zip\n",
        "!unzip -o /content/data/fma_metadata.zip -d /content/data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lists the tracks.csv file inside the metadata folder to confirm that it was successfully extracted. The -lh flag displays the file’s size and permissions in a readable format, while grep tracks.csv filters the output to show only that specific file entry."
      ],
      "metadata": {
        "id": "akMkurDIKry5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/data/fma_metadata/tracks.csv | grep tracks.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdt4Wotk2fRQ",
        "outputId": "3a252c14-e6e3-4059-b729-0363141a5ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-r--r--r-- 1 root root 249M Apr  1  2017 /content/data/fma_metadata/tracks.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads detailed track metadata and links each entry to its corresponding MP3 file in the FMA-small dataset. The function reads the multi-index CSV structure, extracts each track’s title, top genre, and artist, then constructs the correct audio file path using the track ID format (000/000002.mp3). It returns a list of dictionaries holding all relevant info. The final line filters this list to include only records whose audio files actually exist, ensuring later processing runs only on valid data."
      ],
      "metadata": {
        "id": "5VFrDytYKvq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY1agJzmcJO2"
      },
      "outputs": [],
      "source": [
        "AUDIO_ROOT = \"/content/fma_small\"\n",
        "\n",
        "def load_tracks_csv(csv_path: str):\n",
        "    # Load multi-index CSV\n",
        "    df = pd.read_csv(csv_path, header=[0, 1], index_col=0)\n",
        "\n",
        "    rows = []\n",
        "    for track_id, row in df.iterrows():\n",
        "        title = row[('track', 'title')]\n",
        "        genre = row[('track', 'genre_top')]\n",
        "        artist = row[('artist', 'name')]\n",
        "\n",
        "        # Build path to audio file for FMA small\n",
        "        track_id_int = int(track_id)\n",
        "        folder = f\"{track_id_int:03d}\"[:3]\n",
        "        filename = f\"{track_id_int:06d}.mp3\"\n",
        "        audio_path = os.path.join(\"/content/fma_small\", folder, filename)\n",
        "\n",
        "        rows.append({\n",
        "            \"track_id\": track_id,\n",
        "            \"title\": title,\n",
        "            \"artist\": artist,\n",
        "            \"genre\": genre,\n",
        "            \"path\": audio_path\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "TRACKS_CSV = \"/content/data/fma_metadata/tracks.csv\"\n",
        "metas = load_tracks_csv(TRACKS_CSV)\n",
        "metas_existing = [m for m in metas if os.path.exists(m[\"path\"])]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a dedicated data directory if it doesn’t already exist, ensuring a clean location for outputs. It then defines the full path for features_parallel.csv, which will store all extracted audio features once the feature extraction process is completed."
      ],
      "metadata": {
        "id": "VXd5uBapK4QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "FEATURES_CSV = os.path.join(DATA_DIR, \"features_parallel.csv\")"
      ],
      "metadata": {
        "id": "wJ4EhodsfGd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implements the main MFCC-based feature extraction pipeline for each audio track. The _mget helper safely retrieves values from either dictionaries or objects, allowing flexibility in how metadata is stored.\n",
        "mfcc_features() converts a power spectrogram into a mel-scaled representation, then takes its logarithm to approximate human hearing perception. From this log-mel matrix, it computes 13 Mel-Frequency Cepstral Coefficients (MFCCs), which summarize the spectral envelope of the sound. Each coefficient’s mean and standard deviation are calculated across time, forming a compact, time-invariant descriptor for the clip. If enabled, delta and delta-delta features capture how these coefficients change over time. Finally, invalid or infinite values are replaced with zeros for numerical stability.\n",
        "extract_features_for_track() loads a centered 30-second clip, extracts spectral and MFCC features, merges them with track metadata, and returns the complete feature dictionary. If an audio file is missing or an error occurs, the function prints a warning but continues running, ensuring the pipeline remains robust during batch processing."
      ],
      "metadata": {
        "id": "wEEDYEuLJRjg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSLcJ3R-Y_n8"
      },
      "outputs": [],
      "source": [
        "# MFCC FEATURES\n",
        "\n",
        "from typing import Dict, Optional, Any\n",
        "\n",
        "def _mget(meta, key, default=None):\n",
        "    \"\"\"Helper to get key from dict or attribute from object.\"\"\"\n",
        "    if isinstance(meta, dict):\n",
        "        return meta.get(key, default)\n",
        "    return getattr(meta, key, default)\n",
        "\n",
        "\n",
        "def mfcc_features(S_power: np.ndarray, sr: int) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute MFCC stats from a power spectrogram S_power (|STFT|^2).\n",
        "    \"\"\"\n",
        "    # Mel-spectrogram (power)\n",
        "    mel = librosa.feature.melspectrogram(S=S_power, sr=sr, n_mels=N_MELS)\n",
        "\n",
        "    # Log-mel in dB\n",
        "    log_mel = librosa.power_to_db(mel + 1e-10)\n",
        "\n",
        "    # MFCC directly from log-mel\n",
        "    mfcc = librosa.feature.mfcc(S=log_mel, sr=sr, n_mfcc=N_MFCC)\n",
        "\n",
        "    feats: Dict[str, float] = {}\n",
        "\n",
        "    # Aggregate mean and std across time for each coefficient\n",
        "    for i in range(N_MFCC):\n",
        "        coeff = mfcc[i]\n",
        "        feats[f\"mfcc_{i+1}_mean\"] = float(np.nanmean(coeff))\n",
        "        feats[f\"mfcc_{i+1}_std\"]  = float(np.nanstd(coeff))\n",
        "\n",
        "    if INCLUDE_DELTAS:\n",
        "        d1 = librosa.feature.delta(mfcc)\n",
        "        d2 = librosa.feature.delta(mfcc, order=2)\n",
        "        for i in range(N_MFCC):\n",
        "            feats[f\"mfcc_delta_{i+1}_mean\"]       = float(np.nanmean(d1[i]))\n",
        "            feats[f\"mfcc_delta_{i+1}_std\"]        = float(np.nanstd(d1[i]))\n",
        "            feats[f\"mfcc_deltadelta_{i+1}_mean\"]  = float(np.nanmean(d2[i]))\n",
        "            feats[f\"mfcc_deltadelta_{i+1}_std\"]   = float(np.nanstd(d2[i]))\n",
        "\n",
        "    # Final cleanup: replace NaN/Inf with 0.0\n",
        "    for k, v in list(feats.items()):\n",
        "        if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))):\n",
        "            feats[k] = 0.0\n",
        "\n",
        "    return feats\n",
        "\n",
        "def extract_features_for_track(meta: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
        "    try:\n",
        "        # Load a centered clip\n",
        "        path = _mget(meta, \"path\")\n",
        "        if not path:\n",
        "            raise ValueError(\"Missing audio path in meta\")\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Audio not found at {path}\")\n",
        "\n",
        "        y, sr = load_audio_centered(path, sr=SR, clip_seconds=CLIP_SECONDS)\n",
        "\n",
        "        # Your spectral features function should return (dict, S_power)\n",
        "        spec_feats, S_power = spectral_features(y, sr)\n",
        "\n",
        "        # MFCC features from S_power\n",
        "        mfcc_feats = mfcc_features(S_power, sr)\n",
        "\n",
        "        # Merge and attach metadata\n",
        "        feats: Dict[str, Any] = {**spec_feats, **mfcc_feats}\n",
        "        feats.update({\n",
        "            \"track_id\": _mget(meta, \"track_id\"),\n",
        "            \"title\": _mget(meta, \"title\"),\n",
        "            \"artist\": _mget(meta, \"artist\"),\n",
        "            \"genre\": _mget(meta, \"genre\"),\n",
        "            \"path\": path,\n",
        "        })\n",
        "        return feats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Failed {_mget(meta, 'track_id', 'unknown')}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the full FMA-small metadata and builds a reference table linking each track to its corresponding MP3 file. The function reads the multi-index CSV, extracts key details like title, top genre, and artist, and reconstructs the correct audio path based on the track ID format used in the dataset. It returns a list of dictionaries, each representing one track with both metadata and file path. After loading, the print statements confirm how many tracks were found and display the first entry for verification."
      ],
      "metadata": {
        "id": "knnIJX_VJuZ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMP1AU2Jf3SL",
        "outputId": "829a480e-7eb2-4bc6-c23c-3d1a068058ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 106574 tracks.\n",
            "{'track_id': 2, 'title': 'Food', 'artist': 'AWOL', 'genre': 'Hip-Hop', 'path': '/content/fma_small/002/000002.mp3'}\n"
          ]
        }
      ],
      "source": [
        "# Feature Table\n",
        "\n",
        "AUDIO_ROOT = \"/content/fma_small\"\n",
        "\n",
        "def load_tracks_csv(csv_path: str):\n",
        "    # Load multi-index CSV\n",
        "    df = pd.read_csv(csv_path, header=[0, 1], index_col=0)\n",
        "\n",
        "    rows = []\n",
        "    for track_id, row in df.iterrows():\n",
        "        title = row[('track', 'title')]\n",
        "        genre = row[('track', 'genre_top')]\n",
        "        artist = row[('artist', 'name')]\n",
        "\n",
        "        # Build path to audio file for FMA small\n",
        "        track_id_int = int(track_id)\n",
        "        folder = f\"{track_id_int:03d}\"[:3]\n",
        "        filename = f\"{track_id_int:06d}.mp3\"\n",
        "        audio_path = os.path.join(\"/content/fma_small\", folder, filename)\n",
        "\n",
        "        rows.append({\n",
        "            \"track_id\": track_id,\n",
        "            \"title\": title,\n",
        "            \"artist\": artist,\n",
        "            \"genre\": genre,\n",
        "            \"path\": audio_path\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "    TRACKS_CSV = \"/content/data/fma_metadata/tracks.csv\"\n",
        "metas = load_tracks_csv(TRACKS_CSV)\n",
        "print(f\"Loaded {len(metas)} tracks.\")\n",
        "print(metas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reconstructs valid audio paths for every track and filters out missing files. The helper function build_fma_small_path() formats each track ID into the proper folder and filename structure used in the FMA-small dataset (e.g., fma_small/000/000123.mp3). It then updates the path field for every metadata entry and keeps only those whose audio files actually exist. Finally, it prints the total number of metadata rows and how many audio files were successfully located, providing a quick integrity check of the dataset setup."
      ],
      "metadata": {
        "id": "b0mVEg4ZJ8kc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_6DzFB5gNrF",
        "outputId": "39b958d8-b982-408c-f082-23cee74019c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total metadata rows: 106574\n",
            "Audio files found:   5230 (should be ~8000 for fma_small)\n",
            "{'track_id': 2, 'title': 'Food', 'artist': 'AWOL', 'genre': 'Hip-Hop', 'path': '/content/fma_small/000/000002.mp3'}\n"
          ]
        }
      ],
      "source": [
        "AUDIO_ROOT = \"/content/fma_small\"\n",
        "\n",
        "def build_fma_small_path(track_id: int, audio_root=AUDIO_ROOT) -> str:\n",
        "    tid = int(track_id)\n",
        "    folder = f\"{tid:06d}\"[:3]\n",
        "    filename = f\"{tid:06d}.mp3\"\n",
        "    return os.path.join(audio_root, folder, filename)\n",
        "\n",
        "\n",
        "for m in metas:\n",
        "    m[\"path\"] = build_fma_small_path(m[\"track_id\"])\n",
        "\n",
        "# Filter to tracks whose audio actually exists\n",
        "metas_existing = [m for m in metas if os.path.exists(m[\"path\"])]\n",
        "\n",
        "print(f\"Total metadata rows: {len(metas)}\")\n",
        "print(f\"Audio files found:   {len(metas_existing)} (should be ~8000 for fma_small)\")\n",
        "print(metas_existing[0] if metas_existing else \"No audio files found; check unzip path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sets up parallel feature extraction with joblib and checkpoints results to disk. Environment vars cap BLAS threads to avoid CPU oversubscription. run_parallel picks n_jobs (CPU-1 by default), slices metadata into batches, and runs extract_features_for_track in separate processes (backend=\"loky\"). After each batch, successful rows are appended to out_csv in append mode, so progress is saved even if the run stops mid-way. The in-memory rows list is cleared after each write to limit RAM; the function returns only any remaining unsaved rows (use the CSV as the canonical output when out_csv is set)."
      ],
      "metadata": {
        "id": "NhCYiMubJ-5J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJbj6Ok8unnG"
      },
      "outputs": [],
      "source": [
        "!pip -q install joblib\n",
        "\n",
        "import os, pandas as pd, multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "def process_one(meta):\n",
        "    return extract_features_for_track(meta)  # already defined earlier\n",
        "\n",
        "def run_parallel(metas, n_jobs=None, batch_size=100, out_csv=None):\n",
        "    \"\"\"\n",
        "    Parallel feature extraction with joblib and periodic CSV saving.\n",
        "    \"\"\"\n",
        "    if n_jobs is None:\n",
        "        n_jobs = max(1, multiprocessing.cpu_count() - 1)\n",
        "\n",
        "    rows = []\n",
        "    for start in tqdm(range(0, len(metas), batch_size), desc=\"Extracting (parallel)\"):\n",
        "        chunk = metas[start:start+batch_size]\n",
        "        results = Parallel(n_jobs=n_jobs, backend=\"loky\", prefer=\"processes\")(\n",
        "            delayed(process_one)(m) for m in chunk\n",
        "        )\n",
        "        good = [r for r in results if r is not None]\n",
        "        rows.extend(good)\n",
        "\n",
        "        # Save partial results\n",
        "        if out_csv and len(good) > 0:\n",
        "            mode = \"a\" if os.path.exists(out_csv) else \"w\"\n",
        "            header = not os.path.exists(out_csv)\n",
        "            pd.DataFrame(good).to_csv(out_csv, mode=mode, header=header, index=False)\n",
        "            rows = []\n",
        "\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runs the full feature extraction pipeline on all existing tracks in parallel. The run_parallel function processes audio files in batches, extracts their spectral and MFCC features, and periodically writes them to the CSV defined by FEATURES_CSV. Once complete, the collected results are converted into a pandas DataFrame called feat_df, which holds the complete feature table ready for normalization, similarity computation, or model evaluation."
      ],
      "metadata": {
        "id": "1XXxZKSfKKM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBxBf9XXqqFA",
        "outputId": "7ca01d8a-2967-47d2-f347-89a9a408c918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting (parallel):  83%|████████▎ | 44/53 [31:17<06:16, 41.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed 99134: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting (parallel):  92%|█████████▏| 49/53 [34:44<02:45, 41.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed 108925: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting (parallel): 100%|██████████| 53/53 [36:58<00:00, 41.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed 113063: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rows = run_parallel(metas_existing, n_jobs=None, batch_size=100, out_csv=FEATURES_CSV)\n",
        "feat_df = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the previously saved feature dataset from features_parallel.csv into a pandas DataFrame. The print(feat_df.shape) command then displays the number of rows and columns, giving a quick overview of how many tracks were processed and how many features were extracted per track."
      ],
      "metadata": {
        "id": "nQftu1VLQ2Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES_CSV = \"/content/data/features_parallel.csv\"\n",
        "feat_df = pd.read_csv(FEATURES_CSV)\n",
        "print(feat_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkvwUSYxoHU5",
        "outputId": "69210eab-e072-47c5-ecd4-ba96d7fc8b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7327, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performs sequential (non-parallel) feature extraction and builds a complete feature table. The helper _mget safely retrieves metadata fields whether stored as a dictionary or object. The main function extract_features_for_track() loads each track’s audio, extracts its spectral and MFCC features, merges them with metadata like title and genre, and returns a combined dictionary.\n",
        "The loop iterates over all valid tracks, displaying progress with tqdm and collecting feature dictionaries into a list. This list is then converted into a pandas DataFrame, feat_df, which summarizes the number of successfully processed tracks and total extracted feature columns ready for scaling and similarity analysis."
      ],
      "metadata": {
        "id": "yoLXba-tRJT0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BVHu3tWgdrv",
        "outputId": "d88385ea-3a29-4cd7-df2d-942677b0ae69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  85%|████████▌ | 4471/5230 [31:26<03:45,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed 99134: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features:  94%|█████████▍| 4904/5230 [34:27<01:37,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed 108925: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 5230/5230 [36:40<00:00,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed 113063: \n",
            "Tracks with features: 5227, Columns: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def _mget(meta, key, default=None):\n",
        "\n",
        "    if isinstance(meta, dict):\n",
        "        return meta.get(key, default)\n",
        "    return getattr(meta, key, default)\n",
        "\n",
        "def extract_features_for_track(meta):\n",
        "    try:\n",
        "        path = _mget(meta, \"path\")\n",
        "        if not path:\n",
        "            raise ValueError(\"Missing audio path in meta\")\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Audio not found at {path}\")\n",
        "\n",
        "        # Load audio\n",
        "        y, sr = load_audio_centered(path, sr=SR, clip_seconds=CLIP_SECONDS)\n",
        "\n",
        "        # Feature blocks\n",
        "        spec_feats, S_power = spectral_features(y, sr)\n",
        "        mfcc_feats = mfcc_features(S_power, sr)\n",
        "\n",
        "        # Merge + attach metadata\n",
        "        feats = {**spec_feats, **mfcc_feats}\n",
        "        feats.update({\n",
        "            \"track_id\": _mget(meta, \"track_id\"),\n",
        "            \"title\": _mget(meta, \"title\"),\n",
        "            \"artist\": _mget(meta, \"artist\"),\n",
        "            \"genre\": _mget(meta, \"genre\"),\n",
        "            \"path\": path,\n",
        "        })\n",
        "        return feats\n",
        "\n",
        "    except Exception as e:\n",
        "        tid = _mget(meta, \"track_id\", \"unknown\")\n",
        "        print(f\"[WARN] Failed {tid}: {e}\")\n",
        "        return None\n",
        "\n",
        "rows = []\n",
        "for m in tqdm(metas_existing, desc=\"Extracting features\"):\n",
        "    feats = extract_features_for_track(m)\n",
        "    if feats is not None:\n",
        "        rows.append(feats)\n",
        "\n",
        "feat_df = pd.DataFrame(rows)\n",
        "print(f\"Tracks with features: {len(feat_df)}, Columns: {feat_df.shape[1] if len(feat_df)>0 else 0}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepares the extracted features for recommendation by standardizing and computing pairwise similarity. Non-numeric columns like titles and genres are excluded, leaving only feature columns. Any infinite or missing values are replaced with column means to maintain consistency. The StandardScaler then normalizes all features so they share a comparable range, improving similarity accuracy. Finally, cosine_similarity computes how closely each track’s feature vector matches others, producing a similarity matrix (sim_mat) where higher values indicate greater resemblance. Self similarities are set to zero to prevent a track from recommending itself."
      ],
      "metadata": {
        "id": "snT6TJXySBUh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvyf3TdHvY_h"
      },
      "outputs": [],
      "source": [
        "# Standardize + Similarity Index\n",
        "\n",
        "# Select numeric columns for modeling\n",
        "meta_cols = [\"track_id\", \"title\", \"artist\", \"genre\", \"path\"]\n",
        "num_cols = [c for c in feat_df.columns if c not in meta_cols]\n",
        "\n",
        "# Handle any NaNs\n",
        "feat_df[num_cols] = feat_df[num_cols].replace([np.inf, -np.inf], np.nan).fillna(feat_df[num_cols].mean())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(feat_df[num_cols].values)\n",
        "\n",
        "# Precompute cosine similarity matrix\n",
        "sim_mat = cosine_similarity(X)\n",
        "np.fill_diagonal(sim_mat, 0.0) # ignore self-similarity in retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implements the retrieval stage of the recommender system, where similar tracks are ranked for any given seed song. It first creates lookup tables: idx2meta links DataFrame indices to track metadata, and title_artist2idx allows quick index retrieval by song title and artist.\n",
        "The function topk_for_index() retrieves cosine similarity scores for a track, sorts them in descending order, and returns the top-K most similar tracks along with their similarity values. The test loop then selects one or two seed tracks, computes their nearest neighbors, and displays the results as a small ranked table showing each neighbor’s title, artist, genre, and similarity score. This effectively demonstrates how the system finds and lists musically related tracks based on extracted spectral and MFCC features."
      ],
      "metadata": {
        "id": "GpvkMOhFSpXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "yB4nAAJYvtyy",
        "outputId": "2d1a15ac-bdd2-4e3a-e392-7f93a45e00bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Seed: Food — AWOL\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Rank  Track ID              Title              Artist         Genre  \\\n",
              "0     1       664      Must Be a Hit                Laws       Hip-Hop   \n",
              "1     2      5001          Cold Spot     Waylon Thornton          Rock   \n",
              "2     3      3426           Oblivion  The Pleasure Kills          Rock   \n",
              "3     4      3164            For You               Cvees       Hip-Hop   \n",
              "4     5      2931        Best Friend       Seek Six Sick          Rock   \n",
              "5     6      3439            Sadness           Gurdonark  Experimental   \n",
              "6     7      1227          TIME/Leap           St. LaRok       Hip-Hop   \n",
              "7     8      3437             Ritual      Ambient Fabric  Experimental   \n",
              "8     9       666  110% (radio edit)                Laws       Hip-Hop   \n",
              "9    10      2100               Food                AWOL       Hip-Hop   \n",
              "\n",
              "   Similarity  \n",
              "0       0.908  \n",
              "1       0.895  \n",
              "2       0.886  \n",
              "3       0.875  \n",
              "4       0.858  \n",
              "5       0.852  \n",
              "6       0.843  \n",
              "7       0.839  \n",
              "8       0.837  \n",
              "9       0.836  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e97ce741-f546-41a7-bd35-87c9e4d59421\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Track ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>664</td>\n",
              "      <td>Must Be a Hit</td>\n",
              "      <td>Laws</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5001</td>\n",
              "      <td>Cold Spot</td>\n",
              "      <td>Waylon Thornton</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3426</td>\n",
              "      <td>Oblivion</td>\n",
              "      <td>The Pleasure Kills</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3164</td>\n",
              "      <td>For You</td>\n",
              "      <td>Cvees</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2931</td>\n",
              "      <td>Best Friend</td>\n",
              "      <td>Seek Six Sick</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>3439</td>\n",
              "      <td>Sadness</td>\n",
              "      <td>Gurdonark</td>\n",
              "      <td>Experimental</td>\n",
              "      <td>0.852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1227</td>\n",
              "      <td>TIME/Leap</td>\n",
              "      <td>St. LaRok</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>3437</td>\n",
              "      <td>Ritual</td>\n",
              "      <td>Ambient Fabric</td>\n",
              "      <td>Experimental</td>\n",
              "      <td>0.839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>666</td>\n",
              "      <td>110% (radio edit)</td>\n",
              "      <td>Laws</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>2100</td>\n",
              "      <td>Food</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e97ce741-f546-41a7-bd35-87c9e4d59421')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e97ce741-f546-41a7-bd35-87c9e4d59421 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e97ce741-f546-41a7-bd35-87c9e4d59421');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-57eb5115-cb04-4612-9324-cbe17ec4c4c4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57eb5115-cb04-4612-9324-cbe17ec4c4c4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-57eb5115-cb04-4612-9324-cbe17ec4c4c4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f867eff9-d7ee-4035-802f-f3f3cb904d61\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_neighbors')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f867eff9-d7ee-4035-802f-f3f3cb904d61 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_neighbors');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_neighbors",
              "summary": "{\n  \"name\": \"df_neighbors\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Track ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1410,\n        \"min\": 664,\n        \"max\": 5001,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          666,\n          5001,\n          3439\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"110% (radio edit)\",\n          \"Cold Spot\",\n          \"Sadness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Artist\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Ambient Fabric\",\n          \"Waylon Thornton\",\n          \"Gurdonark\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Hip-Hop\",\n          \"Rock\",\n          \"Experimental\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026349994729073924,\n        \"min\": 0.836,\n        \"max\": 0.908,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.837,\n          0.895,\n          0.852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Seed: This World — AWOL\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Rank  Track ID                              Title  \\\n",
              "0     1      3558                 Beloved Girlfriend   \n",
              "1     2      5003                       Come On Down   \n",
              "2     3      4436                               1967   \n",
              "3     4      4430                                '92   \n",
              "4     5       667                    Deranged Barber   \n",
              "5     6       665  Speak Your Mind feat. Hard Target   \n",
              "6     7      4841                        Ticking eye   \n",
              "7     8      4526                        Falcon Hood   \n",
              "8     9      5020                     The Great Cape   \n",
              "9    10      1883            Believe In Me (Reprise)   \n",
              "\n",
              "                                 Artist         Genre  Similarity  \n",
              "0                                 Kraus          Rock       0.861  \n",
              "1                       Waylon Thornton          Rock       0.851  \n",
              "2                                   et_          Rock       0.845  \n",
              "3                               BADLUCK       Hip-Hop       0.833  \n",
              "4                            Majik Most       Hip-Hop       0.823  \n",
              "5                                  Laws       Hip-Hop       0.816  \n",
              "6  I Was A Teenage Strangler Soundtrack  Instrumental       0.815  \n",
              "7                        Podington Bear    Electronic       0.812  \n",
              "8                            Kid Flicks           Pop       0.807  \n",
              "9                      13adluck & uh-oh       Hip-Hop       0.802  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-173331a3-bdb3-468e-b562-b5ff24ef6978\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Track ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3558</td>\n",
              "      <td>Beloved Girlfriend</td>\n",
              "      <td>Kraus</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5003</td>\n",
              "      <td>Come On Down</td>\n",
              "      <td>Waylon Thornton</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4436</td>\n",
              "      <td>1967</td>\n",
              "      <td>et_</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4430</td>\n",
              "      <td>'92</td>\n",
              "      <td>BADLUCK</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>667</td>\n",
              "      <td>Deranged Barber</td>\n",
              "      <td>Majik Most</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>665</td>\n",
              "      <td>Speak Your Mind feat. Hard Target</td>\n",
              "      <td>Laws</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>4841</td>\n",
              "      <td>Ticking eye</td>\n",
              "      <td>I Was A Teenage Strangler Soundtrack</td>\n",
              "      <td>Instrumental</td>\n",
              "      <td>0.815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>4526</td>\n",
              "      <td>Falcon Hood</td>\n",
              "      <td>Podington Bear</td>\n",
              "      <td>Electronic</td>\n",
              "      <td>0.812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>5020</td>\n",
              "      <td>The Great Cape</td>\n",
              "      <td>Kid Flicks</td>\n",
              "      <td>Pop</td>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1883</td>\n",
              "      <td>Believe In Me (Reprise)</td>\n",
              "      <td>13adluck &amp; uh-oh</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>0.802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-173331a3-bdb3-468e-b562-b5ff24ef6978')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-173331a3-bdb3-468e-b562-b5ff24ef6978 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-173331a3-bdb3-468e-b562-b5ff24ef6978');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4771e400-8c92-4d82-ab46-aa3ad7dd6a33\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4771e400-8c92-4d82-ab46-aa3ad7dd6a33')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4771e400-8c92-4d82-ab46-aa3ad7dd6a33 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_07cca467-59b5-47e5-8cc9-3b65cdb9328c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_neighbors')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_07cca467-59b5-47e5-8cc9-3b65cdb9328c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_neighbors');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_neighbors",
              "summary": "{\n  \"name\": \"df_neighbors\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Track ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1758,\n        \"min\": 665,\n        \"max\": 5020,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5020,\n          5003,\n          665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The Great Cape\",\n          \"Come On Down\",\n          \"Speak Your Mind feat. Hard Target\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Artist\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Kid Flicks\",\n          \"Waylon Thornton\",\n          \"Laws\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Hip-Hop\",\n          \"Pop\",\n          \"Instrumental\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020056863607697418,\n        \"min\": 0.802,\n        \"max\": 0.861,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.807,\n          0.851,\n          0.816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Top-K Neighbors for given index\n",
        "\n",
        "TOPK = 10\n",
        "\n",
        "# Build lookup tables\n",
        "idx2meta = {i: m for i, m in enumerate(metas_existing)}\n",
        "title_artist2idx = {(m['title'].strip().lower(), m['artist'].strip().lower()): i\n",
        "                    for i, m in enumerate(metas_existing)}\n",
        "\n",
        "def topk_for_index(idx: int, k: int = TOPK):\n",
        "    sims = sim_mat[idx]\n",
        "    nn_idx = np.argsort(-sims)[:k]\n",
        "    return [(int(j), float(sims[j])) for j in nn_idx]\n",
        "\n",
        "# spot-check\n",
        "for idx in [0, min(1, len(feat_df)-1)]:\n",
        "    seed = feat_df.iloc[idx]\n",
        "    nns = topk_for_index(idx, k=TOPK)\n",
        "\n",
        "    print(f\"\\nSeed: {seed['title']} — {seed['artist']}\")\n",
        "\n",
        "    # Convert neighbors to table rows\n",
        "    table = []\n",
        "    for rank, (j, s) in enumerate(nns, start=1):\n",
        "        row = feat_df.iloc[j]\n",
        "        table.append({\n",
        "            \"Rank\": rank,\n",
        "            \"Track ID\": j,\n",
        "            \"Title\": row['title'],\n",
        "            \"Artist\": row['artist'],\n",
        "            \"Genre\": row.get('genre', 'Unknown'),\n",
        "            \"Similarity\": round(s, 3)\n",
        "        })\n",
        "\n",
        "    df_neighbors = pd.DataFrame(table)\n",
        "    display(df_neighbors)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines quick evaluation utilities for the recommender system. feature_stability_v2 measures how consistent a track’s timbre is by taking two random 5-second segments from the same song, computing MFCC means for each, and returning their Pearson correlation (higher ≈ more stable features; returns NaN on short/silent clips). evaluate_artist_at_k reports the share of seed tracks whose Top-K neighbors include at least one song by the same artist (a sanity check that neighbors aren’t random). evaluate_genre_purity_at_k averages, across seeds, the fraction of Top-K neighbors that share the seed’s genre (higher purity suggests genre-coherent neighborhoods). evaluate_mrr_same_artist computes Mean Reciprocal Rank of the first same-artist neighbor for each seed using cosine similarities (higher means same-artist appears nearer the top). Notes for future-you: the trials argument in feature_stability_v2 isn’t used; consider averaging multiple segment pairs. And in evaluate_mrr_same_artist, the return is indented inside the loop over seeds—move it outside that loop to actually average across all seeds."
      ],
      "metadata": {
        "id": "YZk81DUCS2-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GyNEQ0Jy_3q"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "# Implement: Feature Stability, Artist@K, Genre Purity@K, and MRR for same-artist positives\n",
        "\n",
        "def _mget(meta, key, default=None):\n",
        "    return meta.get(key, default) if isinstance(meta, dict) else getattr(meta, key, default)\n",
        "\n",
        "def _mfcc_means_from_segment(y, sr, seg_seconds=5, n_mfcc=20):\n",
        "    seg_len = int(seg_seconds * sr)\n",
        "    if len(y) < seg_len + 1:\n",
        "        return None\n",
        "    start = np.random.randint(0, max(1, len(y) - seg_len))\n",
        "    seg = y[start:start + seg_len]\n",
        "\n",
        "    S_power = np.abs(librosa.stft(seg))**2\n",
        "    mel = librosa.feature.melspectrogram(S=S_power, sr=sr, n_mels=128)\n",
        "    log_mel = librosa.power_to_db(mel + 1e-10)\n",
        "    mfcc = librosa.feature.mfcc(S=log_mel, sr=sr, n_mfcc=n_mfcc)\n",
        "    return np.nanmean(mfcc, axis=1)\n",
        "\n",
        "def feature_stability_v2(meta, trials: int = 2):\n",
        "    \"\"\"Correlation between two MFCC-mean vectors from different segments of the same track.\"\"\"\n",
        "    path = _mget(meta, \"path\")\n",
        "    if not path:\n",
        "        raise ValueError(\"Meta missing 'path'\")\n",
        "    y, sr = load_audio_centered(path, sr=SR, clip_seconds=CLIP_SECONDS)\n",
        "    if y is None or len(y) < 4 * sr:\n",
        "        return np.nan\n",
        "\n",
        "    x1 = _mfcc_means_from_segment(y, sr)\n",
        "    x2 = _mfcc_means_from_segment(y, sr)\n",
        "    if x1 is None or x2 is None:\n",
        "        return np.nan\n",
        "\n",
        "    if np.allclose(np.std(x1), 0) or np.allclose(np.std(x2), 0):\n",
        "        return np.nan\n",
        "    return float(np.corrcoef(x1, x2)[0, 1])\n",
        "\n",
        "\n",
        "def evaluate_artist_at_k(seed_indices: list, k: int = TOPK):\n",
        "    if not EVAL_ARTIST:\n",
        "        return None\n",
        "    hits = 0\n",
        "    denom = 0\n",
        "    for i in seed_indices:\n",
        "        seed_artist = str(feat_df.iloc[i][\"artist\"]).strip().lower()\n",
        "        if len(seed_artist) == 0:\n",
        "            continue\n",
        "        denom += 1\n",
        "        nns = topk_for_index(i, k)\n",
        "        found = False\n",
        "        for j, _ in nns:\n",
        "            if str(feat_df.iloc[j][\"artist\"]).strip().lower() == seed_artist:\n",
        "                found = True\n",
        "                break\n",
        "        hits += int(found)\n",
        "    return hits / denom if denom > 0 else np.nan\n",
        "\n",
        "def evaluate_genre_purity_at_k(seed_indices: list, k: int = TOPK):\n",
        "    if not EVAL_GENRE:\n",
        "        return None\n",
        "    purities = []\n",
        "    for i in seed_indices:\n",
        "        seed_genre = str(feat_df.iloc[i][\"genre\"]).strip().lower()\n",
        "        if len(seed_genre) == 0:\n",
        "            continue\n",
        "        nns = topk_for_index(i, k)\n",
        "        same = 0\n",
        "        for j, _ in nns:\n",
        "            if str(feat_df.iloc[j][\"genre\"]).strip().lower() == seed_genre:\n",
        "               same += 1\n",
        "        purities.append(same / k)\n",
        "    return float(np.mean(purities)) if purities else np.nan\n",
        "\n",
        "\n",
        "def evaluate_mrr_same_artist(seed_indices: list, k: int = TOPK):\n",
        "    ranks = []\n",
        "    for i in seed_indices:\n",
        "        seed_artist = str(feat_df.iloc[i][\"artist\"]).strip().lower()\n",
        "        if len(seed_artist) == 0:\n",
        "            continue\n",
        "        sims = sim_mat[i]\n",
        "        order = np.argsort(-sims)\n",
        "        # find first index with same artist\n",
        "        rr = 0.0\n",
        "        for rank, j in enumerate(order[:max(50, k)], start=1):\n",
        "            if str(feat_df.iloc[j][\"artist\"]).strip().lower() == seed_artist:\n",
        "                rr = 1.0 / rank\n",
        "                break\n",
        "        if rr > 0:\n",
        "            ranks.append(rr)\n",
        "        return float(np.mean(ranks)) if ranks else np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prints diagnostic information to verify dataset integrity and feature stability. The first line confirms that each metadata entry is stored as a dictionary and shows its available keys (like track_id, title, artist, genre, path). The next line displays a sample audio file path to confirm proper file structure. Finally, it runs feature_stability_v2 on one track to compute the correlation between MFCC means from two random segments, giving a quick sense of how stable that track’s spectral features are."
      ],
      "metadata": {
        "id": "yykndbrqYxbm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3APEcrE6Aqje",
        "outputId": "9f4e3f5f-7052-4bbf-9d8b-7ebf6f75a04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'> ['track_id', 'title', 'artist', 'genre', 'path']\n",
            "Sample path: /content/fma_small/000/000002.mp3\n",
            "One stability value (v2): 0.9888729527098878\n"
          ]
        }
      ],
      "source": [
        "print(type(metas_existing[0]), list(metas_existing[0].keys()))\n",
        "print(\"Sample path:\", metas_existing[0][\"path\"])\n",
        "print(\"One stability value (v2):\", feature_stability_v2(metas_existing[0], trials=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updates the reference for the feature stability function. It deletes any old version of feature_stability from memory (ignoring errors if it doesn’t exist) and then reassigns the name to feature_stability_v2. This ensures that any later calls to feature_stability() use the updated implementation without having to rename it elsewhere in the notebook."
      ],
      "metadata": {
        "id": "-Q9rtmhCY8iy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WpgbnR0BSxN"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    del feature_stability #remove previous version from memeory\n",
        "except NameError:\n",
        "    pass\n",
        "feature_stability = feature_stability_v2  # point the name to the new dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly selects a subset of 500 tracks from the available metadata to serve as the evaluation sample. The random seed ensures consistent sampling across runs. It then creates a mapping between each metadata object and its index position in the full dataset, allowing evaluation functions to reference the correct similarity matrix rows. Finally, it prints how many tracks were chosen, confirming that the evaluation subset has been successfully prepared."
      ],
      "metadata": {
        "id": "7dOOM86wZMS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur57Zm5kB8kx",
        "outputId": "eef6ac14-cfd8-4eec-a512-b85e42992c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 500 tracks for evaluation\n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "\n",
        "EVAL_SIZE = 500\n",
        "metas_eval = random.sample(metas_existing, EVAL_SIZE)  # subset of dicts\n",
        "\n",
        "# map the subset back to their row indices (to use with sim_mat)\n",
        "meta_to_idx = {id(m): i for i, m in enumerate(metas_existing)}\n",
        "seed_indices = [meta_to_idx[id(m)] for m in metas_eval]\n",
        "print(f\"Using {len(metas_eval)} tracks for evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluates the recommender system’s overall performance using stability and similarity-based metrics. For each track in the 500-sample evaluation subset, it computes feature stability by correlating MFCC mean vectors from two random segments, collecting the results in stabs. The mean stability score reflects how consistently the system represents a track’s timbre across time.\n",
        "Next, three retrieval metrics are computed: Artist@K (how often a same-artist song appears among the top-K recommendations), Genre Purity@K (average proportion of neighbors sharing the same genre), and MRR (Mean Reciprocal Rank for the first same-artist match). The fmt() helper formats these metrics to three decimal places or prints “nan” for invalid results.\n",
        "Finally, all scores are printed together, giving a concise summary of how stable, artist-consistent, and genre-coherent the recommender’s retrieved results are."
      ],
      "metadata": {
        "id": "ojPCsRRQilAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mevmleO5cLb",
        "outputId": "a4851f7c-ac3b-4762-8604-a120c962fc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stability (MFCC means corr): 100%|██████████| 500/500 [02:03<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation ===\n",
            "Feature Stability (MFCC means corr): 0.966\n",
            "Artist@10: 0.226\n",
            "Genre Purity@10: 0.218\n",
            "MRR (same-artist within top ~50): nan\n"
          ]
        }
      ],
      "source": [
        "# Stability across tracks\n",
        "\n",
        "stabs = []\n",
        "for m in tqdm(metas_eval, desc=\"Stability (MFCC means corr)\"):\n",
        "    s = feature_stability(m, trials=2)\n",
        "    try:\n",
        "        stabs.append(float(s))\n",
        "    except Exception:\n",
        "        stabs.append(np.nan)\n",
        "\n",
        "stab_arr = np.asarray(stabs, dtype=float)\n",
        "stability_mean = float(np.nanmean(stab_arr)) if np.isfinite(stab_arr).any() else np.nan\n",
        "\n",
        "artist_at_k  = evaluate_artist_at_k(seed_indices, k=TOPK)\n",
        "genre_purity = evaluate_genre_purity_at_k(seed_indices, k=TOPK)\n",
        "mrr          = evaluate_mrr_same_artist(seed_indices, k=TOPK)\n",
        "\n",
        "def fmt(x):\n",
        "    return \"nan\" if not (isinstance(x, (int, float)) and np.isfinite(x)) else f\"{x:.3f}\"\n",
        "\n",
        "print(\"\\n=== Evaluation ===\")\n",
        "print(f\"Feature Stability (MFCC means corr): {fmt(stability_mean)}\")\n",
        "print(f\"Artist@{TOPK}: {fmt(artist_at_k)}\")\n",
        "print(f\"Genre Purity@{TOPK}: {fmt(genre_purity)}\")\n",
        "print(f\"MRR (same-artist within top ~50): {fmt(mrr)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separates MFCC features from other spectral features to test their individual contribution to similarity results. The code first identifies all MFCC-related columns by name and groups the remaining numeric ones as general spectral features. It then builds a MFCC-only feature matrix, standardizes it with StandardScaler for consistent scaling, and computes pairwise cosine similarity between tracks based solely on their MFCC vectors. Self-similarity values are set to zero, preparing this matrix for comparison or retrieval evaluation focused only on timbral characteristics."
      ],
      "metadata": {
        "id": "aeX2mpPhiv0C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "520j6srtGLNu"
      },
      "outputs": [],
      "source": [
        "# Identify columns\n",
        "mfcc_cols = [c for c in feat_df.columns if c.startswith(\"mfcc_\")]\n",
        "spectral_cols = [c for c in feat_df.columns if c not in meta_cols + mfcc_cols]\n",
        "\n",
        "# MFCC-only pipeline\n",
        "X_mfcc = StandardScaler().fit_transform(feat_df[mfcc_cols].values)\n",
        "sim_mfcc = cosine_similarity(X_mfcc)\n",
        "np.fill_diagonal(sim_mfcc, 0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performs an ablation test to compare how well MFCC-only features perform versus the full feature set (MFCC + spectral). The helper function eval_artist_at_k_with_sim() iterates through all tracks, checking whether a same-artist song appears within the top-K most similar tracks using a given similarity matrix. It computes the ratio of successful hits to total evaluated tracks as the final Artist@K score.\n",
        "Two evaluations are run: one using the MFCC-only similarity matrix (sim_mfcc) and another using the combined model’s similarity results (sim_mat). The printed results directly compare how much timbre-based (MFCC) features alone contribute to artist-level retrieval accuracy versus when additional spectral descriptors are included."
      ],
      "metadata": {
        "id": "ZxjDOurGjCVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Artist@K for a sim matrix\n",
        "\n",
        "def eval_artist_at_k_with_sim(sim_matrix, k: int = TOPK):\n",
        "  hits = 0\n",
        "  denom = 0\n",
        "  for i in range(len(feat_df)):\n",
        "      seed_artist = str(feat_df.iloc[i][\"artist\"]).strip().lower()\n",
        "      if len(seed_artist) == 0:\n",
        "          continue\n",
        "      denom += 1\n",
        "      sims = sim_matrix[i]\n",
        "      order = np.argsort(-sims)[:k]\n",
        "      found = False\n",
        "      for j in order:\n",
        "          if str(feat_df.iloc[j][\"artist\"]).strip().lower() == seed_artist:\n",
        "              found = True\n",
        "              break\n",
        "      hits += int(found)\n",
        "  return hits / denom if denom > 0 else np.nan\n",
        "\n",
        "artist_at_k_mfcc = eval_artist_at_k_with_sim(sim_mfcc, k=TOPK)\n",
        "artist_at_k_combined = evaluate_artist_at_k(seed_indices, k=TOPK)\n",
        "\n",
        "print(\"\\n=== Ablation (Artist@K) ===\")\n",
        "print(f\"MFCC-only: {artist_at_k_mfcc:.3f}\")\n",
        "print(f\"MFCC+Spectral: {artist_at_k_combined:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1evq5mr2pojG",
        "outputId": "8c555d5e-d6f1-4f7e-b477-a1cb36d57f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Ablation (Artist@K) ===\n",
            "MFCC-only: 0.717\n",
            "MFCC+Spectral: 0.226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implements a simple retrieval interface for generating recommendations by track ID. It first builds a dictionary mapping each track_id to its row index in the feature DataFrame for quick lookup. The recommend_by_track_id() function takes a given track ID, retrieves its index, and uses the precomputed similarity matrix to find its top-K most similar tracks.\n",
        "For each recommended track, it collects details such as title, artist, and similarity score into a small DataFrame for easy viewing. The printed message confirms which seed track the recommendations are based on, while the returned DataFrame presents the final ranked list of similar songs, forming the user-facing output of the recommender system.\n",
        "\n"
      ],
      "metadata": {
        "id": "BDFv-T_Jj7nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval API for report\n",
        "\n",
        "INDEX_BY_ID = {tid: i for i, tid in enumerate(feat_df[\"track_id\"]) }\n",
        "\n",
        "def recommend_by_track_id(track_id: str, k: int = TOPK):\n",
        "    idx = INDEX_BY_ID.get(track_id, None)\n",
        "    if idx is None:\n",
        "        raise KeyError(f\"Unknown track_id: {track_id}\")\n",
        "    nns = topk_for_index(idx, k=k)\n",
        "    rows = []\n",
        "    seed = feat_df.iloc[idx]\n",
        "    for j, s in nns:\n",
        "        row = feat_df.iloc[j]\n",
        "        rows.append({\n",
        "            \"seed_track_id\": seed[\"track_id\"],\n",
        "            \"seed_title\": seed[\"title\"],\n",
        "            \"seed_artist\": seed[\"artist\"],\n",
        "            \"rec_track_id\": row[\"track_id\"],\n",
        "            \"rec_title\": row[\"title\"],\n",
        "            \"rec_artist\": row[\"artist\"],\n",
        "            \"similarity\": round(float(s), 4),\n",
        "            })\n",
        "    df = pd.DataFrame(rows)\n",
        "    print(f\"✅ Top {k} recommendations for track ID {track_id} — {seed['title']} by {seed['artist']}\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "Pa4euexksF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieves and displays the top 5 recommended tracks for the first entry in your feature dataset. It takes that track’s ID, passes it to recommend_by_track_id(), and returns a small DataFrame showing similar tracks ranked by cosine similarity. Each row lists the seed track’s details alongside a recommended track’s title, artist, and similarity score effectively demonstrating how your recommender suggests musically related songs from the dataset."
      ],
      "metadata": {
        "id": "p5d8og_PkMGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_id = int(feat_df[\"track_id\"].iloc[0])\n",
        "recommend_by_track_id(some_id, k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "4FFIraMOtw_w",
        "outputId": "93491262-c21f-4eaa-d6cd-a2c15db0ceb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Top 5 recommendations for track ID 2 — Food by AWOL\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   seed_track_id seed_title seed_artist  rec_track_id  \\\n",
              "0              2       Food        AWOL         18887   \n",
              "1              2       Food        AWOL         66538   \n",
              "2              2       Food        AWOL         49070   \n",
              "3              2       Food        AWOL         37423   \n",
              "4              2       Food        AWOL         33446   \n",
              "\n",
              "                   rec_title                            rec_artist  similarity  \n",
              "0                Best Friend                         Seek Six Sick      0.9154  \n",
              "1              Pass The Ring                       Waylon Thornton      0.9065  \n",
              "2  Bologna Soundcheck 031105                       Justice Yeldham      0.8982  \n",
              "3               Crimson Snow  Church Of When The Shit Hits The Fan      0.8822  \n",
              "4              Mad About You                             Yair Yona      0.8722  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b612fae0-53de-4b94-a50c-1206272afb24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed_track_id</th>\n",
              "      <th>seed_title</th>\n",
              "      <th>seed_artist</th>\n",
              "      <th>rec_track_id</th>\n",
              "      <th>rec_title</th>\n",
              "      <th>rec_artist</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Food</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>18887</td>\n",
              "      <td>Best Friend</td>\n",
              "      <td>Seek Six Sick</td>\n",
              "      <td>0.9154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Food</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>66538</td>\n",
              "      <td>Pass The Ring</td>\n",
              "      <td>Waylon Thornton</td>\n",
              "      <td>0.9065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Food</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>49070</td>\n",
              "      <td>Bologna Soundcheck 031105</td>\n",
              "      <td>Justice Yeldham</td>\n",
              "      <td>0.8982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Food</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>37423</td>\n",
              "      <td>Crimson Snow</td>\n",
              "      <td>Church Of When The Shit Hits The Fan</td>\n",
              "      <td>0.8822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Food</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>33446</td>\n",
              "      <td>Mad About You</td>\n",
              "      <td>Yair Yona</td>\n",
              "      <td>0.8722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b612fae0-53de-4b94-a50c-1206272afb24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b612fae0-53de-4b94-a50c-1206272afb24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b612fae0-53de-4b94-a50c-1206272afb24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3eb5b5bd-4614-4965-90af-3391b3e350d7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3eb5b5bd-4614-4965-90af-3391b3e350d7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3eb5b5bd-4614-4965-90af-3391b3e350d7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"recommend_by_track_id(some_id, k=5)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"seed_track_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Food\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_artist\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AWOL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rec_track_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17861,\n        \"min\": 18887,\n        \"max\": 66538,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          66538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rec_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Pass The Ring\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rec_artist\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Waylon Thornton\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017622996340009838,\n        \"min\": 0.8722,\n        \"max\": 0.9154,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prints a concise summary of all evaluation metrics in a readable report format. It displays the average feature stability score (MFCC correlation across segments), Artist@K, Genre Purity@K, and Mean Reciprocal Rank (MRR), showing how consistent, artist-aware, and genre-coherent the recommender is. The final line compares results from the MFCC-only and combined feature models, revealing how additional spectral features impact recommendation accuracy. This block serves as the system’s final quantitative performance summary."
      ],
      "metadata": {
        "id": "o70QpvVokZay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Feature stability (MFCC means corr): {stability_mean:.3f}\")\n",
        "print(f\"Artist@{TOPK}: {artist_at_k:.3f}\")\n",
        "print(f\"Genre Purity@{TOPK}: {genre_purity:.3f}\")\n",
        "print(f\"MRR (same-artist within top ~50): {mrr:.3f}\")\n",
        "print(f\"Ablation Artist@{TOPK} — MFCC-only: {artist_at_k_mfcc:.3f} | Combined: {artist_at_k_combined:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRRfVzuYjXWH",
        "outputId": "a88989bf-23a1-46c3-9430-0c34f399afd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature stability (MFCC means corr): 0.969\n",
            "Artist@10: 0.226\n",
            "Genre Purity@10: 0.218\n",
            "MRR (same-artist within top ~50): nan\n",
            "Ablation Artist@10 — MFCC-only: 0.717 | Combined: 0.226\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
